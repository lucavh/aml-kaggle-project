{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import random \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from skimage import io, transform\n",
    "from skimage.transform import resize\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanktonDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, list_IDs, labels, img_dir, transform=None):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.transform = transform\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        \n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "        \n",
    "        img_name = os.path.join(self.img_dir,ID)\n",
    "        X = io.imread(img_name)\n",
    "        \n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        \n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X, y, img_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "These classes should return the image object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \n",
    "        h, w = image.shape\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        return img\n",
    "    \n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        img = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        return img\n",
    "    \n",
    "class ResizePadded(object):\n",
    "    \"\"\"Padd the image so it will be rectangular.\"\"\"\n",
    "    \n",
    "    def __init__(self, order=1):\n",
    "        self.order = order\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        desired_size = max(image.shape)\n",
    "        old_size = image.shape\n",
    "\n",
    "        delta_w = desired_size - old_size[1]\n",
    "        delta_h = desired_size - old_size[0]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "        if (top <= 0):\n",
    "            top = 1\n",
    "        if (bottom <= 0):\n",
    "            bottom = 1\n",
    "        if (left <= 0):\n",
    "            left = 1\n",
    "        if (right <= 0):\n",
    "            right = 1\n",
    "            \n",
    "        color = [1, 1, 1]\n",
    "        new_im = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "        return new_im\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W \n",
    "        # torch image: C X H X W\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        return torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "training_data = pd.read_csv('train_onelabel.csv')\n",
    "IDs_train = training_data['image'].tolist()\n",
    "random.shuffle(IDs_train)\n",
    "\n",
    "# Labels of trained images  \n",
    "labels_train = dict(zip(training_data['image'], training_data['class']))\n",
    "\n",
    "# Testing data\n",
    "testing_data = pd.read_csv('sample.csv')\n",
    "IDs_test = testing_data['image'].tolist()\n",
    "\n",
    "# Labels of trained images  \n",
    "labels_test = dict(zip(testing_data['image'], testing_data['class']))\n",
    "\n",
    "partition = {}\n",
    "partition['train'] = IDs_train\n",
    "partition['validation'] = IDs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_epochs = 25\n",
    "batch_size = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "resize_scale = 36\n",
    "crop = 32\n",
    "padd_size = (400, 400)\n",
    "num_classes = pd.read_csv('label_map.txt',header=None).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "training_set = PlanktonDataset(partition['train'], \n",
    "                               labels_train, \n",
    "                               img_dir='train_images/',\n",
    "                               transform=transforms.Compose([Rescale(resize_scale),RandomCrop(crop),ToTensor()]))\n",
    "training_generator = data.DataLoader(dataset=training_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "validation_set = PlanktonDataset(partition['validation'], \n",
    "                               labels_test, \n",
    "                               img_dir='test_images/',\n",
    "                               transform=transforms.Compose([Rescale(resize_scale),RandomCrop(crop),ToTensor()]))\n",
    "validation_generator = data.DataLoader(dataset=validation_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing if everything worked so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(training_set)):\n",
    "    \n",
    "    sample = training_set[i+10]\n",
    "    x = sample[0]\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    plt.imshow(sample[0][0,:,:],cmap='gray')\n",
    "\n",
    "    if i == 3:\n",
    "        #plt.show()\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(8*8*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN();\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/25, Iter : 5/0,  Loss: 4.0812\n",
      "Epoch : 1/25, Iter : 10/0,  Loss: 3.7302\n",
      "Epoch : 1/25, Iter : 15/0,  Loss: 3.5052\n",
      "Epoch : 1/25, Iter : 20/0,  Loss: 3.3091\n",
      "Epoch : 1/25, Iter : 25/0,  Loss: 3.0755\n",
      "Epoch : 2/25, Iter : 5/0,  Loss: 2.9930\n",
      "Epoch : 2/25, Iter : 10/0,  Loss: 2.9078\n",
      "Epoch : 2/25, Iter : 15/0,  Loss: 2.9077\n",
      "Epoch : 2/25, Iter : 20/0,  Loss: 2.7715\n",
      "Epoch : 2/25, Iter : 25/0,  Loss: 2.7244\n",
      "Epoch : 3/25, Iter : 5/0,  Loss: 2.6868\n",
      "Epoch : 3/25, Iter : 10/0,  Loss: 2.6385\n",
      "Epoch : 3/25, Iter : 15/0,  Loss: 2.6430\n",
      "Epoch : 3/25, Iter : 20/0,  Loss: 2.5811\n",
      "Epoch : 3/25, Iter : 25/0,  Loss: 2.5412\n",
      "Epoch : 4/25, Iter : 5/0,  Loss: 2.5338\n",
      "Epoch : 4/25, Iter : 10/0,  Loss: 2.4517\n",
      "Epoch : 4/25, Iter : 15/0,  Loss: 2.4793\n",
      "Epoch : 4/25, Iter : 20/0,  Loss: 2.4882\n",
      "Epoch : 4/25, Iter : 25/0,  Loss: 2.4614\n",
      "Epoch : 5/25, Iter : 5/0,  Loss: 2.3108\n",
      "Epoch : 5/25, Iter : 10/0,  Loss: 2.2933\n",
      "Epoch : 5/25, Iter : 15/0,  Loss: 2.1914\n",
      "Epoch : 5/25, Iter : 20/0,  Loss: 2.2946\n",
      "Epoch : 5/25, Iter : 25/0,  Loss: 2.4209\n",
      "Epoch : 6/25, Iter : 5/0,  Loss: 2.1293\n",
      "Epoch : 6/25, Iter : 10/0,  Loss: 2.1609\n",
      "Epoch : 6/25, Iter : 15/0,  Loss: 2.2624\n",
      "Epoch : 6/25, Iter : 20/0,  Loss: 2.2532\n",
      "Epoch : 6/25, Iter : 25/0,  Loss: 2.1613\n",
      "Epoch : 7/25, Iter : 5/0,  Loss: 2.1570\n",
      "Epoch : 7/25, Iter : 10/0,  Loss: 2.1396\n",
      "Epoch : 7/25, Iter : 15/0,  Loss: 2.1306\n",
      "Epoch : 7/25, Iter : 20/0,  Loss: 2.0665\n",
      "Epoch : 7/25, Iter : 25/0,  Loss: 2.1979\n",
      "Epoch : 8/25, Iter : 5/0,  Loss: 2.0322\n",
      "Epoch : 8/25, Iter : 10/0,  Loss: 2.0881\n",
      "Epoch : 8/25, Iter : 15/0,  Loss: 2.0749\n",
      "Epoch : 8/25, Iter : 20/0,  Loss: 2.0449\n",
      "Epoch : 8/25, Iter : 25/0,  Loss: 2.1725\n",
      "Epoch : 9/25, Iter : 5/0,  Loss: 2.0728\n",
      "Epoch : 9/25, Iter : 10/0,  Loss: 2.0800\n",
      "Epoch : 9/25, Iter : 15/0,  Loss: 2.0231\n",
      "Epoch : 9/25, Iter : 20/0,  Loss: 2.1354\n",
      "Epoch : 9/25, Iter : 25/0,  Loss: 1.8200\n",
      "Epoch : 10/25, Iter : 5/0,  Loss: 2.0687\n",
      "Epoch : 10/25, Iter : 10/0,  Loss: 1.9984\n",
      "Epoch : 10/25, Iter : 15/0,  Loss: 1.9924\n",
      "Epoch : 10/25, Iter : 20/0,  Loss: 1.9021\n",
      "Epoch : 10/25, Iter : 25/0,  Loss: 1.9584\n",
      "Epoch : 11/25, Iter : 5/0,  Loss: 1.9278\n",
      "Epoch : 11/25, Iter : 10/0,  Loss: 1.9182\n",
      "Epoch : 11/25, Iter : 15/0,  Loss: 1.9288\n",
      "Epoch : 11/25, Iter : 20/0,  Loss: 1.9952\n",
      "Epoch : 11/25, Iter : 25/0,  Loss: 2.0769\n",
      "Epoch : 12/25, Iter : 5/0,  Loss: 1.9160\n",
      "Epoch : 12/25, Iter : 10/0,  Loss: 1.8749\n",
      "Epoch : 12/25, Iter : 15/0,  Loss: 2.0059\n",
      "Epoch : 12/25, Iter : 20/0,  Loss: 1.8710\n",
      "Epoch : 12/25, Iter : 25/0,  Loss: 2.1428\n",
      "Epoch : 13/25, Iter : 5/0,  Loss: 1.9130\n",
      "Epoch : 13/25, Iter : 10/0,  Loss: 1.9255\n",
      "Epoch : 13/25, Iter : 15/0,  Loss: 1.8754\n",
      "Epoch : 13/25, Iter : 20/0,  Loss: 1.8783\n",
      "Epoch : 13/25, Iter : 25/0,  Loss: 1.8859\n",
      "Epoch : 14/25, Iter : 5/0,  Loss: 1.8178\n",
      "Epoch : 14/25, Iter : 10/0,  Loss: 1.8418\n",
      "Epoch : 14/25, Iter : 15/0,  Loss: 1.8269\n",
      "Epoch : 14/25, Iter : 20/0,  Loss: 1.9601\n",
      "Epoch : 14/25, Iter : 25/0,  Loss: 1.8078\n",
      "Epoch : 15/25, Iter : 5/0,  Loss: 1.8949\n",
      "Epoch : 15/25, Iter : 10/0,  Loss: 1.8313\n",
      "Epoch : 15/25, Iter : 15/0,  Loss: 1.8048\n",
      "Epoch : 15/25, Iter : 20/0,  Loss: 1.8551\n",
      "Epoch : 15/25, Iter : 25/0,  Loss: 1.8729\n",
      "Epoch : 16/25, Iter : 5/0,  Loss: 1.8375\n",
      "Epoch : 16/25, Iter : 10/0,  Loss: 1.8544\n",
      "Epoch : 16/25, Iter : 15/0,  Loss: 1.7796\n",
      "Epoch : 16/25, Iter : 20/0,  Loss: 1.8499\n",
      "Epoch : 16/25, Iter : 25/0,  Loss: 1.7824\n",
      "Epoch : 17/25, Iter : 5/0,  Loss: 1.7999\n",
      "Epoch : 17/25, Iter : 10/0,  Loss: 1.7235\n",
      "Epoch : 17/25, Iter : 15/0,  Loss: 1.8506\n",
      "Epoch : 17/25, Iter : 20/0,  Loss: 1.7042\n",
      "Epoch : 17/25, Iter : 25/0,  Loss: 1.8818\n",
      "Epoch : 18/25, Iter : 5/0,  Loss: 1.7239\n",
      "Epoch : 18/25, Iter : 10/0,  Loss: 1.7346\n",
      "Epoch : 18/25, Iter : 15/0,  Loss: 1.7216\n",
      "Epoch : 18/25, Iter : 20/0,  Loss: 1.7795\n",
      "Epoch : 18/25, Iter : 25/0,  Loss: 1.4999\n",
      "Epoch : 19/25, Iter : 5/0,  Loss: 1.7578\n",
      "Epoch : 19/25, Iter : 10/0,  Loss: 1.8047\n",
      "Epoch : 19/25, Iter : 15/0,  Loss: 1.7549\n",
      "Epoch : 19/25, Iter : 20/0,  Loss: 1.7622\n",
      "Epoch : 19/25, Iter : 25/0,  Loss: 1.6686\n",
      "Epoch : 20/25, Iter : 5/0,  Loss: 1.6463\n",
      "Epoch : 20/25, Iter : 10/0,  Loss: 1.6419\n",
      "Epoch : 20/25, Iter : 15/0,  Loss: 1.7330\n",
      "Epoch : 20/25, Iter : 20/0,  Loss: 1.6986\n",
      "Epoch : 20/25, Iter : 25/0,  Loss: 1.6400\n",
      "Epoch : 21/25, Iter : 5/0,  Loss: 1.7170\n",
      "Epoch : 21/25, Iter : 10/0,  Loss: 1.7166\n",
      "Epoch : 21/25, Iter : 15/0,  Loss: 1.5974\n",
      "Epoch : 21/25, Iter : 20/0,  Loss: 1.7521\n",
      "Epoch : 21/25, Iter : 25/0,  Loss: 1.8276\n",
      "Epoch : 22/25, Iter : 5/0,  Loss: 1.7383\n",
      "Epoch : 22/25, Iter : 10/0,  Loss: 1.7218\n",
      "Epoch : 22/25, Iter : 15/0,  Loss: 1.7375\n",
      "Epoch : 22/25, Iter : 20/0,  Loss: 1.7654\n",
      "Epoch : 22/25, Iter : 25/0,  Loss: 1.6910\n",
      "Epoch : 23/25, Iter : 5/0,  Loss: 1.7934\n",
      "Epoch : 23/25, Iter : 10/0,  Loss: 1.6701\n",
      "Epoch : 23/25, Iter : 15/0,  Loss: 1.6967\n",
      "Epoch : 23/25, Iter : 20/0,  Loss: 1.5648\n",
      "Epoch : 23/25, Iter : 25/0,  Loss: 1.8679\n",
      "Epoch : 24/25, Iter : 5/0,  Loss: 1.6789\n",
      "Epoch : 24/25, Iter : 10/0,  Loss: 1.7345\n",
      "Epoch : 24/25, Iter : 15/0,  Loss: 1.6983\n",
      "Epoch : 24/25, Iter : 20/0,  Loss: 1.6844\n",
      "Epoch : 24/25, Iter : 25/0,  Loss: 1.5903\n",
      "Epoch : 25/25, Iter : 5/0,  Loss: 1.6850\n",
      "Epoch : 25/25, Iter : 10/0,  Loss: 1.6294\n",
      "Epoch : 25/25, Iter : 15/0,  Loss: 1.6631\n",
      "Epoch : 25/25, Iter : 20/0,  Loss: 1.5680\n",
      "Epoch : 25/25, Iter : 25/0,  Loss: 1.3883\n"
     ]
    }
   ],
   "source": [
    "losses = [];\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels, ids) in enumerate(training_generator):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels)\n",
    "        #print(labels, ids)\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data[0]);\n",
    "        #print(i)\n",
    "        if (i+1) % 5 == 0:\n",
    "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(training_generator)/batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict & save validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels, IDs in validation_generator:\n",
    "    images = Variable(images.float())\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    for i in range(len(predicted)):\n",
    "        results[IDs[i][12:]] = int(predicted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(results, orient='index').reset_index()\n",
    "df_results.columns = ['image', 'class']\n",
    "df_results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
