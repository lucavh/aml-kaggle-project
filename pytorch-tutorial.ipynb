{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch/\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x104cbfd30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a standard random seed for reproducible results\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifardata/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#The compose function allows for multiple transforms\n",
    "#transforms.ToTensor() converts our PILImage to a tensor of shape (C x H x W) in the range [0,1]\n",
    "#transforms.Normalize(mean,std) normalizes a tensor to a (mean, std) for (R, G, B)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./cifardata', train=True, download=True, transform=transform)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='./cifardata', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# designate the possible labels for each image\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "#Training\n",
    "n_training_samples = 20000\n",
    "train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n",
    "\n",
    "#Validation\n",
    "n_val_samples = 5000\n",
    "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n",
    "\n",
    "#Test\n",
    "n_test_samples = 5000\n",
    "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Designing a neural net (data preprocessing)\n",
    "Pytorch makes it pretty easy to implement all of those feature engineering steps that we described above. We’ll be making use of 4 major functions in our CNN class:\n",
    "\n",
    "1. torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding) – applies convolution\n",
    "2. torch.nn.relu(x) – applies ReLU\n",
    "3. torch.nn.MaxPool2d(kernel_size, stride, padding) – applies Max Pooling\n",
    "4. torch.nn.Linear(in_features, out_features) – fully connected layer (multiply inputs by learned weights)\n",
    "\n",
    "Writing CNN code in Pytorch can get a little complex, since everything is defined inside of one class. We’ll create a SimpleCNN class which inherits from the master torch.nn.Module class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    \n",
    "    #Our batch shape for input x is (3, 32, 32)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        #Input channels = 3, output channels = 18\n",
    "        self.conv1 = torch.nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Second layer\n",
    "        #self.conv2 = torch.nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
    "        #self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        #4608 input features, 64 output features (see sizing flow below)\n",
    "        self.fc1 = torch.nn.Linear(18 * 16 * 16, 64)\n",
    "        \n",
    "        #64 input features, 10 output features for our 10 defined classes\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Computes the activation of the first convolution\n",
    "        #Size changes from (3, 32, 32) to (18, 32, 32)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        #Size changes from (18, 32, 32) to (18, 16, 16)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        #Reshape data to input to the input layer of the neural net\n",
    "        #Size changes from (18, 16, 16) to (1, 4608)\n",
    "        #Recall that the -1 infers this dimension from the other given dimension\n",
    "        x = x.view(-1, 18 * 16 *16)\n",
    "        \n",
    "        #Computes the activation of the first fully connected layer\n",
    "        #Size changes from (1, 4608) to (1, 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        #Computes the second fully connected layer (activation applied later)\n",
    "        #Size changes from (1, 64) to (1, 10)\n",
    "        x = self.fc2(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputSize(in_size, kernel_size, stride, padding):\n",
    "\n",
    "    output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n",
    "\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training a neural net\n",
    "Our basic flow is a training loop: each time we pass through the loop (called and “epoch”), we compute a forward pass on the network and implement backpropagation to adjust the weights. We’ll also record some other measurements like loss and time passed, so that we can analyze them as the net trains itself.\n",
    "\n",
    "To start, we’ll define our data loaders using the samplers we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader takes in a dataset and a sampler for loading (num_workers deals with system level memory) \n",
    "def get_train_loader(batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,sampler=train_sampler, num_workers=2)\n",
    "    return(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test and validation loaders have constant batch sizes, so we can define them directly\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, sampler=test_sampler, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(train_set, batch_size=128, sampler=val_sampler, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll also define our loss and optimizer functions that the CNN will use to find the right weights. We’ll be using Cross Entropy Loss (Log Loss) as our loss function, which strongly penalizes high confidence in the wrong answer. The optimizer is the popular Adam algorithm (not a person!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def createLossAndOptimizer(net, learning_rate=0.001):\n",
    "    \n",
    "    #Loss function\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    #Optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return(loss, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we’ll define a function to train our CNN using a simple for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
    "    \n",
    "    #Print all of the hyperparameters of the training iteration:\n",
    "    print(\"===== HYPERPARAMETERS =====\")\n",
    "    print(\"batch_size=\", batch_size)\n",
    "    print(\"epochs=\", n_epochs)\n",
    "    print(\"learning_rate=\", learning_rate)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    #Get training data\n",
    "    train_loader = get_train_loader(batch_size)\n",
    "    n_batches = len(train_loader)\n",
    "    \n",
    "    #Create our loss and optimizer functions\n",
    "    loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
    "    \n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            #Get inputs\n",
    "            inputs, labels = data\n",
    "            \n",
    "            #Wrap them in a Variable object\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            #Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward pass, backward pass, optimize\n",
    "            outputs = net(inputs)\n",
    "            loss_size = loss(outputs, labels)\n",
    "            loss_size.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Print statistics\n",
    "            running_loss += loss_size.data[0]\n",
    "            total_train_loss += loss_size.data[0]\n",
    "            \n",
    "            #Print every 10th batch of an epoch\n",
    "            if (i + 1) % (print_every + 1) == 0:\n",
    "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
    "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
    "                #Reset running loss and time\n",
    "                running_loss = 0.0\n",
    "                start_time = time.time()\n",
    "            \n",
    "        #At the end of the epoch, do a pass on the validation set\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            \n",
    "            #Wrap tensors in Variables\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            #Forward pass\n",
    "            val_outputs = net(inputs)\n",
    "            val_loss_size = loss(val_outputs, labels)\n",
    "            total_val_loss += val_loss_size.data[0]\n",
    "            \n",
    "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
    "        \n",
    "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During each epoch of training, we pass data to the model in batches whose size we define when we call the training loop. Data is feature engineered using the SimpleCNN class we’ve defined, and then basic metrics are printed after a few passes. During each loop, we also calculate the loss on our validation set.\n",
    "\n",
    "To actually train the net now only requires two lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 5\n",
      "learning_rate= 0.001\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/python-3-6/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/anaconda2/envs/python-3-6/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 10% \t train_loss: 2.14 took: 1.27s\n",
      "Epoch 1, 20% \t train_loss: 1.91 took: 1.11s\n",
      "Epoch 1, 30% \t train_loss: 1.78 took: 1.09s\n",
      "Epoch 1, 40% \t train_loss: 1.70 took: 1.09s\n",
      "Epoch 1, 50% \t train_loss: 1.66 took: 1.08s\n",
      "Epoch 1, 60% \t train_loss: 1.56 took: 1.11s\n",
      "Epoch 1, 70% \t train_loss: 1.54 took: 1.18s\n",
      "Epoch 1, 80% \t train_loss: 1.49 took: 1.19s\n",
      "Epoch 1, 90% \t train_loss: 1.52 took: 1.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/python-3-6/lib/python3.6/site-packages/ipykernel_launcher.py:69: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss = 1.38\n",
      "Epoch 2, 10% \t train_loss: 1.37 took: 1.45s\n",
      "Epoch 2, 20% \t train_loss: 1.32 took: 2.09s\n",
      "Epoch 2, 30% \t train_loss: 1.35 took: 2.16s\n",
      "Epoch 2, 40% \t train_loss: 1.37 took: 1.92s\n",
      "Epoch 2, 50% \t train_loss: 1.29 took: 1.77s\n",
      "Epoch 2, 60% \t train_loss: 1.37 took: 1.75s\n",
      "Epoch 2, 70% \t train_loss: 1.28 took: 1.74s\n",
      "Epoch 2, 80% \t train_loss: 1.31 took: 1.75s\n",
      "Epoch 2, 90% \t train_loss: 1.24 took: 1.73s\n",
      "Validation loss = 1.27\n",
      "Epoch 3, 10% \t train_loss: 1.15 took: 1.77s\n",
      "Epoch 3, 20% \t train_loss: 1.17 took: 1.72s\n",
      "Epoch 3, 30% \t train_loss: 1.23 took: 1.74s\n",
      "Epoch 3, 40% \t train_loss: 1.15 took: 1.72s\n",
      "Epoch 3, 50% \t train_loss: 1.17 took: 1.75s\n",
      "Epoch 3, 60% \t train_loss: 1.17 took: 1.74s\n",
      "Epoch 3, 70% \t train_loss: 1.19 took: 1.84s\n",
      "Epoch 3, 80% \t train_loss: 1.16 took: 1.74s\n",
      "Epoch 3, 90% \t train_loss: 1.16 took: 1.73s\n",
      "Validation loss = 1.18\n",
      "Epoch 4, 10% \t train_loss: 1.08 took: 2.02s\n",
      "Epoch 4, 20% \t train_loss: 1.10 took: 1.92s\n",
      "Epoch 4, 30% \t train_loss: 1.06 took: 1.78s\n",
      "Epoch 4, 40% \t train_loss: 1.08 took: 2.10s\n",
      "Epoch 4, 50% \t train_loss: 1.11 took: 2.10s\n",
      "Epoch 4, 60% \t train_loss: 1.10 took: 2.21s\n",
      "Epoch 4, 70% \t train_loss: 1.06 took: 1.77s\n",
      "Epoch 4, 80% \t train_loss: 1.05 took: 1.77s\n",
      "Epoch 4, 90% \t train_loss: 1.09 took: 1.75s\n",
      "Validation loss = 1.19\n",
      "Epoch 5, 10% \t train_loss: 0.96 took: 1.88s\n",
      "Epoch 5, 20% \t train_loss: 1.00 took: 1.78s\n",
      "Epoch 5, 30% \t train_loss: 0.98 took: 1.80s\n",
      "Epoch 5, 40% \t train_loss: 1.01 took: 1.78s\n",
      "Epoch 5, 50% \t train_loss: 0.98 took: 1.78s\n",
      "Epoch 5, 60% \t train_loss: 1.01 took: 1.78s\n",
      "Epoch 5, 70% \t train_loss: 1.02 took: 1.76s\n",
      "Epoch 5, 80% \t train_loss: 1.05 took: 1.76s\n",
      "Epoch 5, 90% \t train_loss: 0.96 took: 1.79s\n",
      "Validation loss = 1.16\n",
      "Training finished, took 91.04s\n"
     ]
    }
   ],
   "source": [
    "CNN = SimpleCNN()\n",
    "trainNet(CNN, batch_size=32, n_epochs=5, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 5\n",
      "learning_rate= 0.001\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/python-3-6/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/anaconda2/envs/python-3-6/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 10% \t train_loss: 2.04 took: 1.39s\n",
      "Epoch 1, 20% \t train_loss: 1.80 took: 1.21s\n",
      "Epoch 1, 30% \t train_loss: 1.72 took: 1.35s\n",
      "Epoch 1, 40% \t train_loss: 1.60 took: 1.73s\n",
      "Epoch 1, 50% \t train_loss: 1.51 took: 1.70s\n",
      "Epoch 1, 60% \t train_loss: 1.49 took: 1.40s\n",
      "Epoch 1, 70% \t train_loss: 1.48 took: 1.70s\n",
      "Epoch 1, 80% \t train_loss: 1.46 took: 4.14s\n",
      "Epoch 1, 90% \t train_loss: 1.47 took: 1.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/python-3-6/lib/python3.6/site-packages/ipykernel_launcher.py:69: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss = 1.37\n",
      "Epoch 2, 10% \t train_loss: 1.32 took: 1.75s\n",
      "Epoch 2, 20% \t train_loss: 1.36 took: 2.03s\n",
      "Epoch 2, 30% \t train_loss: 1.31 took: 1.93s\n",
      "Epoch 2, 40% \t train_loss: 1.28 took: 2.30s\n",
      "Epoch 2, 50% \t train_loss: 1.29 took: 2.83s\n",
      "Epoch 2, 60% \t train_loss: 1.25 took: 2.40s\n",
      "Epoch 2, 70% \t train_loss: 1.28 took: 1.80s\n",
      "Epoch 2, 80% \t train_loss: 1.28 took: 1.79s\n",
      "Epoch 2, 90% \t train_loss: 1.32 took: 2.70s\n",
      "Validation loss = 1.26\n",
      "Epoch 3, 10% \t train_loss: 1.18 took: 3.83s\n",
      "Epoch 3, 20% \t train_loss: 1.18 took: 3.90s\n",
      "Epoch 3, 30% \t train_loss: 1.15 took: 3.25s\n",
      "Epoch 3, 40% \t train_loss: 1.18 took: 2.84s\n",
      "Epoch 3, 50% \t train_loss: 1.17 took: 2.20s\n",
      "Epoch 3, 60% \t train_loss: 1.16 took: 2.09s\n",
      "Epoch 3, 70% \t train_loss: 1.15 took: 2.11s\n",
      "Epoch 3, 80% \t train_loss: 1.19 took: 2.06s\n",
      "Epoch 3, 90% \t train_loss: 1.18 took: 2.17s\n",
      "Validation loss = 1.19\n",
      "Epoch 4, 10% \t train_loss: 1.03 took: 2.25s\n",
      "Epoch 4, 20% \t train_loss: 1.05 took: 2.05s\n",
      "Epoch 4, 30% \t train_loss: 1.05 took: 2.31s\n",
      "Epoch 4, 40% \t train_loss: 1.05 took: 2.08s\n",
      "Epoch 4, 50% \t train_loss: 1.08 took: 2.13s\n",
      "Epoch 4, 60% \t train_loss: 1.07 took: 2.14s\n",
      "Epoch 4, 70% \t train_loss: 1.09 took: 2.18s\n",
      "Epoch 4, 80% \t train_loss: 1.12 took: 2.16s\n",
      "Epoch 4, 90% \t train_loss: 1.10 took: 2.17s\n",
      "Validation loss = 1.18\n",
      "Epoch 5, 10% \t train_loss: 0.95 took: 2.34s\n",
      "Epoch 5, 20% \t train_loss: 0.99 took: 2.24s\n",
      "Epoch 5, 30% \t train_loss: 0.98 took: 2.16s\n",
      "Epoch 5, 40% \t train_loss: 0.96 took: 2.25s\n",
      "Epoch 5, 50% \t train_loss: 0.99 took: 2.13s\n",
      "Epoch 5, 60% \t train_loss: 1.02 took: 2.18s\n",
      "Epoch 5, 70% \t train_loss: 0.98 took: 2.28s\n",
      "Epoch 5, 80% \t train_loss: 1.01 took: 2.19s\n",
      "Epoch 5, 90% \t train_loss: 1.00 took: 2.21s\n",
      "Validation loss = 1.18\n",
      "Training finished, took 117.76s\n"
     ]
    }
   ],
   "source": [
    "CNN = SimpleCNN()\n",
    "trainNet(CNN, batch_size=32, n_epochs=5, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
