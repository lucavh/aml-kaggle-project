{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import random \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from skimage import io, transform\n",
    "from skimage.transform import resize\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanktonDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, list_IDs, labels, img_dir, transform=None):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.transform = transform\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        \n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "        \n",
    "        img_name = os.path.join(self.img_dir,ID)\n",
    "        X = io.imread(img_name)\n",
    "        \n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        \n",
    "        y = self.labels[ID]\n",
    "\n",
    "        return X, y, img_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "These classes should return the image object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \n",
    "        h, w = image.shape\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        return img\n",
    "    \n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        img = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        return img\n",
    "    \n",
    "class ResizePadded(object):\n",
    "    \"\"\"Padd the image so it will be rectangular.\"\"\"\n",
    "    \n",
    "    def __init__(self, order=1):\n",
    "        self.order = order\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        desired_size = max(image.shape)\n",
    "        old_size = image.shape\n",
    "\n",
    "        delta_w = desired_size - old_size[1]\n",
    "        delta_h = desired_size - old_size[0]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "        if (top <= 0):\n",
    "            top = 1\n",
    "        if (bottom <= 0):\n",
    "            bottom = 1\n",
    "        if (left <= 0):\n",
    "            left = 1\n",
    "        if (right <= 0):\n",
    "            right = 1\n",
    "            \n",
    "        color = [1, 1, 1]\n",
    "        new_im = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "        return new_im\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W \n",
    "        # torch image: C X H X W\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        return torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "training_data = pd.read_csv('train_onelabel.csv')\n",
    "IDs_train = training_data['image'].tolist()\n",
    "random.shuffle(IDs_train)\n",
    "\n",
    "# Labels of trained images  \n",
    "labels_train = dict(zip(training_data['image'], training_data['class']))\n",
    "\n",
    "# Testing data\n",
    "testing_data = pd.read_csv('sample.csv')\n",
    "IDs_test = testing_data['image'].tolist()\n",
    "\n",
    "# Labels of trained images  \n",
    "labels_test = dict(zip(testing_data['image'], testing_data['class']))\n",
    "\n",
    "partition = {}\n",
    "partition['train'] = IDs_train\n",
    "partition['validation'] = IDs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_epochs = 25\n",
    "batch_size = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "resize_scale = 36\n",
    "crop = 32\n",
    "padd_size = (400, 400)\n",
    "num_classes = pd.read_csv('label_map.txt',header=None).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "training_set = PlanktonDataset(partition['train'], \n",
    "                               labels_train, \n",
    "                               img_dir='train_images/',\n",
    "                               transform=transforms.Compose([Rescale(resize_scale),RandomCrop(crop),ToTensor()]))\n",
    "training_generator = data.DataLoader(dataset=training_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "validation_set = PlanktonDataset(partition['validation'], \n",
    "                               labels_test, \n",
    "                               img_dir='test_images/',\n",
    "                               transform=transforms.Compose([Rescale(resize_scale),RandomCrop(crop),ToTensor()]))\n",
    "validation_generator = data.DataLoader(dataset=validation_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing if everything worked so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n",
      "torch.Size([1, 32, 32])\n",
      "torch.Size([1, 32, 32])\n",
      "torch.Size([1, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(training_set)):\n",
    "    \n",
    "    sample = training_set[i+10]\n",
    "    x = sample[0]\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    plt.imshow(sample[0][0,:,:],cmap='gray')\n",
    "    print(sample[0].shape)\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(8*8*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN();\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/25, Iter : 5/0,  Loss: 4.0812\n",
      "Epoch : 1/25, Iter : 10/0,  Loss: 3.7302\n",
      "Epoch : 1/25, Iter : 15/0,  Loss: 3.5052\n",
      "Epoch : 1/25, Iter : 20/0,  Loss: 3.3091\n",
      "Epoch : 1/25, Iter : 25/0,  Loss: 3.0755\n",
      "Epoch : 2/25, Iter : 5/0,  Loss: 2.9930\n",
      "Epoch : 2/25, Iter : 10/0,  Loss: 2.9078\n",
      "Epoch : 2/25, Iter : 15/0,  Loss: 2.9077\n",
      "Epoch : 2/25, Iter : 20/0,  Loss: 2.7715\n",
      "Epoch : 2/25, Iter : 25/0,  Loss: 2.7244\n",
      "Epoch : 3/25, Iter : 5/0,  Loss: 2.6868\n",
      "Epoch : 3/25, Iter : 10/0,  Loss: 2.6385\n",
      "Epoch : 3/25, Iter : 15/0,  Loss: 2.6430\n",
      "Epoch : 3/25, Iter : 20/0,  Loss: 2.5811\n",
      "Epoch : 3/25, Iter : 25/0,  Loss: 2.5412\n",
      "Epoch : 4/25, Iter : 5/0,  Loss: 2.5338\n",
      "Epoch : 4/25, Iter : 10/0,  Loss: 2.4517\n",
      "Epoch : 4/25, Iter : 15/0,  Loss: 2.4793\n",
      "Epoch : 4/25, Iter : 20/0,  Loss: 2.4882\n",
      "Epoch : 4/25, Iter : 25/0,  Loss: 2.4614\n",
      "Epoch : 5/25, Iter : 5/0,  Loss: 2.3108\n",
      "Epoch : 5/25, Iter : 10/0,  Loss: 2.2933\n",
      "Epoch : 5/25, Iter : 15/0,  Loss: 2.1914\n",
      "Epoch : 5/25, Iter : 20/0,  Loss: 2.2946\n",
      "Epoch : 5/25, Iter : 25/0,  Loss: 2.4209\n",
      "Epoch : 6/25, Iter : 5/0,  Loss: 2.1293\n",
      "Epoch : 6/25, Iter : 10/0,  Loss: 2.1609\n",
      "Epoch : 6/25, Iter : 15/0,  Loss: 2.2624\n",
      "Epoch : 6/25, Iter : 20/0,  Loss: 2.2532\n",
      "Epoch : 6/25, Iter : 25/0,  Loss: 2.1613\n",
      "Epoch : 7/25, Iter : 5/0,  Loss: 2.1570\n",
      "Epoch : 7/25, Iter : 10/0,  Loss: 2.1396\n",
      "Epoch : 7/25, Iter : 15/0,  Loss: 2.1306\n",
      "Epoch : 7/25, Iter : 20/0,  Loss: 2.0665\n",
      "Epoch : 7/25, Iter : 25/0,  Loss: 2.1979\n",
      "Epoch : 8/25, Iter : 5/0,  Loss: 2.0322\n",
      "Epoch : 8/25, Iter : 10/0,  Loss: 2.0881\n",
      "Epoch : 8/25, Iter : 15/0,  Loss: 2.0749\n",
      "Epoch : 8/25, Iter : 20/0,  Loss: 2.0449\n",
      "Epoch : 8/25, Iter : 25/0,  Loss: 2.1725\n",
      "Epoch : 9/25, Iter : 5/0,  Loss: 2.0728\n",
      "Epoch : 9/25, Iter : 10/0,  Loss: 2.0800\n",
      "Epoch : 9/25, Iter : 15/0,  Loss: 2.0231\n",
      "Epoch : 9/25, Iter : 20/0,  Loss: 2.1354\n",
      "Epoch : 9/25, Iter : 25/0,  Loss: 1.8200\n",
      "Epoch : 10/25, Iter : 5/0,  Loss: 2.0687\n",
      "Epoch : 10/25, Iter : 10/0,  Loss: 1.9984\n",
      "Epoch : 10/25, Iter : 15/0,  Loss: 1.9924\n",
      "Epoch : 10/25, Iter : 20/0,  Loss: 1.9021\n",
      "Epoch : 10/25, Iter : 25/0,  Loss: 1.9584\n",
      "Epoch : 11/25, Iter : 5/0,  Loss: 1.9278\n",
      "Epoch : 11/25, Iter : 10/0,  Loss: 1.9182\n",
      "Epoch : 11/25, Iter : 15/0,  Loss: 1.9288\n",
      "Epoch : 11/25, Iter : 20/0,  Loss: 1.9952\n",
      "Epoch : 11/25, Iter : 25/0,  Loss: 2.0769\n",
      "Epoch : 12/25, Iter : 5/0,  Loss: 1.9160\n",
      "Epoch : 12/25, Iter : 10/0,  Loss: 1.8749\n",
      "Epoch : 12/25, Iter : 15/0,  Loss: 2.0059\n",
      "Epoch : 12/25, Iter : 20/0,  Loss: 1.8710\n",
      "Epoch : 12/25, Iter : 25/0,  Loss: 2.1428\n",
      "Epoch : 13/25, Iter : 5/0,  Loss: 1.9130\n",
      "Epoch : 13/25, Iter : 10/0,  Loss: 1.9255\n",
      "Epoch : 13/25, Iter : 15/0,  Loss: 1.8754\n",
      "Epoch : 13/25, Iter : 20/0,  Loss: 1.8783\n",
      "Epoch : 13/25, Iter : 25/0,  Loss: 1.8859\n",
      "Epoch : 14/25, Iter : 5/0,  Loss: 1.8178\n",
      "Epoch : 14/25, Iter : 10/0,  Loss: 1.8418\n",
      "Epoch : 14/25, Iter : 15/0,  Loss: 1.8269\n",
      "Epoch : 14/25, Iter : 20/0,  Loss: 1.9601\n",
      "Epoch : 14/25, Iter : 25/0,  Loss: 1.8078\n",
      "Epoch : 15/25, Iter : 5/0,  Loss: 1.8949\n",
      "Epoch : 15/25, Iter : 10/0,  Loss: 1.8313\n",
      "Epoch : 15/25, Iter : 15/0,  Loss: 1.8048\n",
      "Epoch : 15/25, Iter : 20/0,  Loss: 1.8551\n",
      "Epoch : 15/25, Iter : 25/0,  Loss: 1.8729\n",
      "Epoch : 16/25, Iter : 5/0,  Loss: 1.8375\n",
      "Epoch : 16/25, Iter : 10/0,  Loss: 1.8544\n",
      "Epoch : 16/25, Iter : 15/0,  Loss: 1.7796\n",
      "Epoch : 16/25, Iter : 20/0,  Loss: 1.8499\n",
      "Epoch : 16/25, Iter : 25/0,  Loss: 1.7824\n",
      "Epoch : 17/25, Iter : 5/0,  Loss: 1.7999\n",
      "Epoch : 17/25, Iter : 10/0,  Loss: 1.7235\n",
      "Epoch : 17/25, Iter : 15/0,  Loss: 1.8506\n",
      "Epoch : 17/25, Iter : 20/0,  Loss: 1.7042\n",
      "Epoch : 17/25, Iter : 25/0,  Loss: 1.8818\n",
      "Epoch : 18/25, Iter : 5/0,  Loss: 1.7239\n",
      "Epoch : 18/25, Iter : 10/0,  Loss: 1.7346\n",
      "Epoch : 18/25, Iter : 15/0,  Loss: 1.7216\n",
      "Epoch : 18/25, Iter : 20/0,  Loss: 1.7795\n",
      "Epoch : 18/25, Iter : 25/0,  Loss: 1.4999\n",
      "Epoch : 19/25, Iter : 5/0,  Loss: 1.7578\n",
      "Epoch : 19/25, Iter : 10/0,  Loss: 1.8047\n",
      "Epoch : 19/25, Iter : 15/0,  Loss: 1.7549\n",
      "Epoch : 19/25, Iter : 20/0,  Loss: 1.7622\n",
      "Epoch : 19/25, Iter : 25/0,  Loss: 1.6686\n",
      "Epoch : 20/25, Iter : 5/0,  Loss: 1.6463\n",
      "Epoch : 20/25, Iter : 10/0,  Loss: 1.6419\n",
      "Epoch : 20/25, Iter : 15/0,  Loss: 1.7330\n",
      "Epoch : 20/25, Iter : 20/0,  Loss: 1.6986\n",
      "Epoch : 20/25, Iter : 25/0,  Loss: 1.6400\n",
      "Epoch : 21/25, Iter : 5/0,  Loss: 1.7170\n",
      "Epoch : 21/25, Iter : 10/0,  Loss: 1.7166\n",
      "Epoch : 21/25, Iter : 15/0,  Loss: 1.5974\n",
      "Epoch : 21/25, Iter : 20/0,  Loss: 1.7521\n",
      "Epoch : 21/25, Iter : 25/0,  Loss: 1.8276\n",
      "Epoch : 22/25, Iter : 5/0,  Loss: 1.7383\n",
      "Epoch : 22/25, Iter : 10/0,  Loss: 1.7218\n",
      "Epoch : 22/25, Iter : 15/0,  Loss: 1.7375\n",
      "Epoch : 22/25, Iter : 20/0,  Loss: 1.7654\n",
      "Epoch : 22/25, Iter : 25/0,  Loss: 1.6910\n",
      "Epoch : 23/25, Iter : 5/0,  Loss: 1.7934\n",
      "Epoch : 23/25, Iter : 10/0,  Loss: 1.6701\n",
      "Epoch : 23/25, Iter : 15/0,  Loss: 1.6967\n",
      "Epoch : 23/25, Iter : 20/0,  Loss: 1.5648\n",
      "Epoch : 23/25, Iter : 25/0,  Loss: 1.8679\n",
      "Epoch : 24/25, Iter : 5/0,  Loss: 1.6789\n",
      "Epoch : 24/25, Iter : 10/0,  Loss: 1.7345\n",
      "Epoch : 24/25, Iter : 15/0,  Loss: 1.6983\n",
      "Epoch : 24/25, Iter : 20/0,  Loss: 1.6844\n",
      "Epoch : 24/25, Iter : 25/0,  Loss: 1.5903\n",
      "Epoch : 25/25, Iter : 5/0,  Loss: 1.6850\n",
      "Epoch : 25/25, Iter : 10/0,  Loss: 1.6294\n",
      "Epoch : 25/25, Iter : 15/0,  Loss: 1.6631\n",
      "Epoch : 25/25, Iter : 20/0,  Loss: 1.5680\n",
      "Epoch : 25/25, Iter : 25/0,  Loss: 1.3883\n"
     ]
    }
   ],
   "source": [
    "losses = [];\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels, ids) in enumerate(training_generator):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels)\n",
    "        #print(labels, ids)\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data[0]);\n",
    "        #print(i)\n",
    "        if (i+1) % 5 == 0:\n",
    "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(training_generator)/batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict & save validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels, IDs in validation_generator:\n",
    "    images = Variable(images.float())\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    for i in range(len(predicted)):\n",
    "        results[IDs[i][12:]] = int(predicted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(results, orient='index').reset_index()\n",
    "df_results.columns = ['image', 'class']\n",
    "df_results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
